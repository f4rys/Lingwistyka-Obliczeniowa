{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f385b140",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import json\n",
    "\n",
    "import torch\n",
    "\n",
    "from modules.training import train_streamed_lm\n",
    "from modules.transformer import TransformerConfig, TransformerLanguageModel\n",
    "from modules.eval import (\n",
    "    iter_hf_texts, evaluate_token_nll,\n",
    "    word_and_char_perplexity, whitespace_oov_stats\n",
    " )\n",
    "from modules.benchmark import (\n",
    "    measure_throughput, measure_generation_latency, \n",
    "    measure_training_step_time\n",
    ")\n",
    "from modules.tokenizers import (\n",
    "    build_pretrained_tokenizer, WhitespaceTokenizer, \n",
    "    build_ws_vocab, SentencePieceTokenizer, \n",
    "    train_sentencepiece, tokenizer_throughput, \n",
    "    avg_tokens_per_word, percent_words_encoded_directly\n",
    ")\n",
    "from modules.device import best_device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e130381e",
   "metadata": {},
   "source": [
    "1. Build tokenizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de3378eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pretrained tokenizer (GPT-2)\n",
    "pretrained_name = 'gpt2'\n",
    "tok_pre = build_pretrained_tokenizer(pretrained_name)\n",
    "vocab_N = tok_pre.vocab_size\n",
    "vocab_N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ba74c842",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a52ec8186d8438fb7485fb23f44df1d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "26428"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Whitespace tokenizer: build vocab from HF StackOverflow train stream (small sample)\n",
    "def head_texts(n=2000):\n",
    "    for ex in iter_hf_texts(split='train'):\n",
    "        yield ex\n",
    "        n -= 1\n",
    "        if n<=0: \n",
    "            break\n",
    "\n",
    "ws_vocab = build_ws_vocab(head_texts(5000), vocab_size=vocab_N) # type: ignore\n",
    "tok_ws = WhitespaceTokenizer(ws_vocab, name_or_path=f'whitespace_{vocab_N}')\n",
    "tok_ws.vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b8a5ba0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1bb2c04b60734bb9b9db5fcff14df606",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/59 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "50257"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SentencePiece tokenizer: train on sampled corpus and load\n",
    "sp_dir = os.path.join('outputs','sentencepiece')\n",
    "os.makedirs(sp_dir, exist_ok=True)\n",
    "sp_input = os.path.join(sp_dir, 'sp_corpus.txt')\n",
    "\n",
    "# Build a ~1MB training corpus different from evaluation sample\n",
    "with open(sp_input, 'w', encoding='utf-8') as f:\n",
    "    bytes_written = 0\n",
    "    for t in iter_hf_texts(split='train'):\n",
    "        f.write(t.replace('\\n',' ')+'\\n')\n",
    "        bytes_written += len(t)\n",
    "        if bytes_written > 1_200_000:\n",
    "            break\n",
    "\n",
    "sp_model = train_sentencepiece(sp_input, model_prefix=os.path.join(\n",
    "    sp_dir,'spm'), vocab_size=vocab_N, model_type='bpe') # type: ignore\n",
    "tok_sp = SentencePieceTokenizer(sp_model, name_or_path=f'spm_{vocab_N}')\n",
    "tok_sp.vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c35cf3d9",
   "metadata": {},
   "source": [
    "2. Train three identical models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "db5938d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained': 50257, 'whitespace': 26428, 'sentencepiece': 50257}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_model(vocab_size: int, pad_id: int|None):\n",
    "    cfg = TransformerConfig(vocab_size=vocab_size, \n",
    "                            pad_token_id=pad_id or 0, \n",
    "                            max_seq_len=256, \n",
    "                            emb_dim=384, \n",
    "                            n_layers=4, \n",
    "                            n_heads=6, \n",
    "                            ff_dim=1536)\n",
    "    return TransformerLanguageModel(cfg), cfg.__dict__\n",
    "\n",
    "tokenizers = {\n",
    "    'pretrained': tok_pre,\n",
    "    'whitespace': tok_ws,\n",
    "    'sentencepiece': tok_sp,\n",
    "}\n",
    "\n",
    "tokenizer_pad = {\n",
    "    k: (getattr(t, 'pad_token_id', None) if getattr(\n",
    "        t, 'pad_token_id', None) is not None else 0)\n",
    "    for k,t in tokenizers.items()\n",
    "}\n",
    "\n",
    "tokenizer_vocab = { k: (t.vocab_size if hasattr(\n",
    "    t,'vocab_size') else t.get_vocab_size()) for k,t in tokenizers.items() }\n",
    "tokenizer_vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9e3186",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for tokenizer: pretrained\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\looxx\\Desktop\\studia\\lingwistyka_obliczeniowa\\Lingwistyka-Obliczeniowa\\.venv\\Lib\\site-packages\\torch\\backends\\__init__.py:46: UserWarning: Please use the new API settings to control TF32 behavior, such as torch.backends.cudnn.conv.fp32_precision = 'tf32' or torch.backends.cuda.matmul.fp32_precision = 'ieee'. Old settings, e.g, torch.backends.cuda.matmul.allow_tf32 = True, torch.backends.cudnn.allow_tf32 = True, allowTF32CuDNN() and allowTF32CuBLAS() will be deprecated after Pytorch 2.9. Please see https://pytorch.org/docs/main/notes/cuda.html#tensorfloat-32-tf32-on-ampere-and-later-devices (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\aten\\src\\ATen\\Context.cpp:85.)\n",
      "  self.setter(val)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n",
      "Resumed from outputs\\pretrained\\checkpoints\\last.pt at epoch 5, step 5000\n",
      "Training complete. Saved to: outputs\\pretrained\\final.pt\n",
      "Training model for tokenizer: whitespace\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\looxx\\Desktop\\studia\\lingwistyka_obliczeniowa\\Lingwistyka-Obliczeniowa\\lab2\\modules\\training.py:190: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_cuda_amp)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on device: cuda\n",
      "Resumed from outputs\\whitespace\\checkpoints\\last.pt at epoch 5, step 5000\n",
      "Training complete. Saved to: outputs\\whitespace\\final.pt\n",
      "Training model for tokenizer: sentencepiece\n",
      "Training on device: cuda\n",
      "Resumed from outputs\\sentencepiece\\checkpoints\\last.pt at epoch 5, step 5000\n",
      "Training complete. Saved to: outputs\\sentencepiece\\final.pt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pretrained': 'outputs\\\\pretrained\\\\final.pt',\n",
       " 'whitespace': 'outputs\\\\whitespace\\\\final.pt',\n",
       " 'sentencepiece': 'outputs\\\\sentencepiece\\\\final.pt'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train loop per tokenizer\n",
    "save_root = os.path.join('outputs')\n",
    "os.makedirs(save_root, exist_ok=True)\n",
    "\n",
    "train_configs = {}\n",
    "final_weights = {}\n",
    "\n",
    "for name, tok in tokenizers.items():\n",
    "    print(f'Training model for tokenizer: {name}')\n",
    "\n",
    "    model, cfg = build_model(tokenizer_vocab[name], tokenizer_pad[name])\n",
    "    ckpt_dir = os.path.join(save_root, name, 'checkpoints')\n",
    "    final_dir = os.path.join(save_root, name)\n",
    "\n",
    "    out = train_streamed_lm(\n",
    "        model, tok, cfg,\n",
    "        ckpt_dir=ckpt_dir, final_dir=final_dir,\n",
    "        batch_size=16, max_length=256, steps_per_epoch=1000, num_epochs=5, save_every=1,\n",
    "        lr=3e-4, warmup_steps=200, grad_clip=1.0,\n",
    "    )\n",
    "\n",
    "    train_configs[name] = cfg\n",
    "    final_weights[name] = out\n",
    "\n",
    "final_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "157bd469",
   "metadata": {},
   "source": [
    "3. Evaluation: word- and character-level perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "37c1b29c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for evaluation: cuda\n",
      "Evaluating tokenizer: pretrained\n",
      "Evaluating tokenizer: whitespace\n",
      "Evaluating tokenizer: sentencepiece\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pretrained': {'avg_token_nll': 7.091267203816032,\n",
       "  'word_ppl': 1861.6299426343217,\n",
       "  'char_ppl': 4.025724676578652,\n",
       "  'eval_tokens': 407},\n",
       " 'whitespace': {'avg_token_nll': 6.418873063535515,\n",
       "  'word_ppl': 613.3115613681346,\n",
       "  'char_ppl': 3.2782911709636395,\n",
       "  'eval_tokens': 381},\n",
       " 'sentencepiece': {'avg_token_nll': 6.786788562736889,\n",
       "  'word_ppl': 1283.7788507666364,\n",
       "  'char_ppl': 3.758276634644433,\n",
       "  'eval_tokens': 404}}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Evaluate models\n",
    "results = {}\n",
    "eval_texts = iter_hf_texts(split='test')\n",
    "\n",
    "# for tokenization stats later, we may need the same texts twice; \n",
    "# so convert to list of limited size\n",
    "eval_texts_list = [t for _, t in zip(range(2000), eval_texts)]\n",
    "\n",
    "dev = best_device()\n",
    "print('Using device for evaluation:', dev)\n",
    "\n",
    "for name, tok in tokenizers.items():\n",
    "    print(f'Evaluating tokenizer: {name}')\n",
    "    model, cfg = build_model(tokenizer_vocab[name], tokenizer_pad[name])\n",
    "\n",
    "    # load final weights\n",
    "    state = torch.load(final_weights[name], map_location='cpu')\n",
    "    model.load_state_dict(state)\n",
    "    model.to(dev)\n",
    "    model.eval()\n",
    "\n",
    "    avg_nll, n_tokens = evaluate_token_nll(\n",
    "        model, tok, eval_texts_list, max_examples=len(eval_texts_list))\n",
    "    word_ppl, char_ppl = word_and_char_perplexity(\n",
    "        avg_nll, tok, eval_texts_list, max_examples=len(eval_texts_list))\n",
    "\n",
    "    results[name] = {\n",
    "        'avg_token_nll': float(avg_nll),\n",
    "        'word_ppl': float(word_ppl),\n",
    "        'char_ppl': float(char_ppl),\n",
    "        'eval_tokens': int(n_tokens),\n",
    "    }\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcfc708",
   "metadata": {},
   "source": [
    "4. OOV and efficiency metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "85e61488",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oov': 14, 'total': 421, 'percent': 3.32541567695962}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# OOV for whitespace\n",
    "ws_vocab_set = set(tok_ws.vocab.itos)\n",
    "oov_count, total_words, pct_oov = whitespace_oov_stats(\n",
    "    ws_vocab_set, eval_texts_list, max_examples=len(eval_texts_list))\n",
    "oov_stats = {'oov': oov_count, 'total': total_words, 'percent': pct_oov}\n",
    "oov_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cd315297",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained': {'tok_per_sec': 214723.0015461261,\n",
       "  'tokens_total': 894,\n",
       "  'avg_tokens_per_word': 1.0617577197149644,\n",
       "  'pct_words_direct': 79.09738717339667,\n",
       "  'vocab_size': 50257},\n",
       " 'whitespace': {'tok_per_sec': 251771.86625793113,\n",
       "  'tokens_total': 842,\n",
       "  'avg_tokens_per_word': 1.0,\n",
       "  'pct_words_direct': 96.67458432304038,\n",
       "  'vocab_size': 26428},\n",
       " 'sentencepiece': {'tok_per_sec': 208646.123578511,\n",
       "  'tokens_total': 888,\n",
       "  'avg_tokens_per_word': 1.0546318289786223,\n",
       "  'pct_words_direct': 95.01187648456056,\n",
       "  'vocab_size': 50257}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Efficiency: tokenizer throughput and avg tokens per word\n",
    "efficiency = {}\n",
    "\n",
    "for name, tok in tokenizers.items():\n",
    "    tps, total = tokenizer_throughput(tok, eval_texts_list, iters=2)\n",
    "    atpw = avg_tokens_per_word(tok, eval_texts_list, max_examples=len(eval_texts_list))\n",
    "    pct_direct = percent_words_encoded_directly(tok, eval_texts_list, max_examples=200)\n",
    "    efficiency[name] = {'tok_per_sec': tps, \n",
    "                        'tokens_total': total, \n",
    "                        'avg_tokens_per_word': atpw, \n",
    "                        'pct_words_direct': pct_direct, \n",
    "                        'vocab_size': tokenizer_vocab[name]}\n",
    "\n",
    "efficiency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5298b91b",
   "metadata": {},
   "source": [
    "6. Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e466da77",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json = {\n",
    "    'ppl': results,\n",
    "    'oov_ws': oov_stats,\n",
    "    'efficiency': efficiency,\n",
    "}\n",
    "\n",
    "res_path = os.path.join('outputs','summary.json')\n",
    "\n",
    "with open(res_path, 'w', encoding='utf-8') as f:\n",
    "    json.dump(save_json, f, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b22ea4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2276"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build ~1MB evaluation buffer (distinct from SP training corpus)\n",
    "def collect_texts_approx_bytes(split='test', target_bytes=1_048_576):\n",
    "    buf = []\n",
    "    total = 0\n",
    "\n",
    "    for t in iter_hf_texts(split=split):\n",
    "        buf.append(t)\n",
    "        total += len(t)\n",
    "        if total >= target_bytes:\n",
    "            break\n",
    "\n",
    "    return buf\n",
    "\n",
    "stats_texts_1mb = collect_texts_approx_bytes('test', 1_100_000)\n",
    "sum(len(x) for x in stats_texts_1mb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0b4e17aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pretrained': {'tok_per_sec': 272725.8546803404,\n",
       "  'tokens_total': 894,\n",
       "  'avg_tokens_per_word': 1.0617577197149644,\n",
       "  'pct_words_direct': 79.09738717339667,\n",
       "  'direct_words': 333,\n",
       "  'total_words': 421,\n",
       "  'vocab_size': 50257},\n",
       " 'whitespace': {'tok_per_sec': 304133.9965552876,\n",
       "  'tokens_total': 842,\n",
       "  'avg_tokens_per_word': 1.0,\n",
       "  'pct_words_direct': 96.67458432304038,\n",
       "  'direct_words': 407,\n",
       "  'total_words': 421,\n",
       "  'vocab_size': 26428},\n",
       " 'sentencepiece': {'tok_per_sec': 183447.86248337684,\n",
       "  'tokens_total': 888,\n",
       "  'avg_tokens_per_word': 1.0546318289786223,\n",
       "  'pct_words_direct': 95.01187648456056,\n",
       "  'direct_words': 400,\n",
       "  'total_words': 421,\n",
       "  'vocab_size': 50257}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Override efficiency metrics using ~1MB test buffer\n",
    "efficiency = {}\n",
    "\n",
    "def direct_word_counts(tokenizer, texts):\n",
    "    # count words encoded as single token and not UNK\n",
    "    word_re = re.compile(r\"\\w+|[^\\w\\s]\", re.UNICODE)\n",
    "    total = 0\n",
    "    direct = 0\n",
    "\n",
    "    for t in texts:\n",
    "        for w in word_re.findall(t):\n",
    "            if not w.strip():\n",
    "                continue\n",
    "\n",
    "            # request tensors so we can safely use .sum() and .tolist()\n",
    "            enc = tokenizer(w, return_tensors='pt', padding=True, truncation=True)\n",
    "            ids = enc['input_ids'][0].tolist()\n",
    "            length = int((enc['attention_mask'][0]).sum().item())\n",
    "            is_unk = hasattr(tokenizer, 'unk_token_id') and (\n",
    "                length==1 and ids[0] == getattr(tokenizer,'unk_token_id'))\n",
    "            if length == 1 and not is_unk:\n",
    "                direct += 1\n",
    "            total += 1\n",
    "\n",
    "    return direct, total, (direct/total*100.0 if total else 0.0)\n",
    "\n",
    "for name, tok in tokenizers.items():\n",
    "    tps, total = tokenizer_throughput(tok, stats_texts_1mb, iters=2)\n",
    "    atpw = avg_tokens_per_word(tok, stats_texts_1mb, max_examples=None)\n",
    "    direct_cnt, direct_total, direct_pct = direct_word_counts(tok, stats_texts_1mb)\n",
    "\n",
    "    efficiency[name] = {'tok_per_sec': tps, \n",
    "                        'tokens_total': total, \n",
    "                        'avg_tokens_per_word': atpw, \n",
    "                        'pct_words_direct': direct_pct, \n",
    "                        'direct_words': direct_cnt, \n",
    "                        'total_words': direct_total, \n",
    "                        'vocab_size': tokenizer_vocab[name]}\n",
    "\n",
    "efficiency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f9cbbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Qualitative: use longer >=30-word samples and show tokens (not just ids)\n",
    "long_samples = [\n",
    "    \" \".join([\"In\", \"Python,\", \"list\", \"comprehensions\", \"provide\", \"a\", \"concise\", \"way\", \"to\", \"create\", \"lists.\", \"They\", \"are\", \"often\", \"faster\", \"than\", \"using\", \"loops,\", \"and\", \"they\", \"express\", \"intent\", \"clearly\", \"when\", \"mapping\", \"and\", \"filtering\", \"collections\", \"in\", \"everyday\", \"data\", \"processing\", \"tasks.\"]),\n",
    "    \" \".join([\"The\", \"quick\", \"brown\", \"fox\", \"jumps\", \"over\", \"the\", \"lazy\", \"dog,\", \"while\", \"the\", \"curious\", \"cat\", \"watches\", \"from\", \"the\", \"windowsill,\", \"pondering\", \"why\", \"humans\", \"keep\", \"typing\", \"this\", \"sentence\", \"to\", \"test\", \"keyboards\", \"and\", \"fonts\", \"across\", \"different\", \"systems.\"]),\n",
    "    \" \".join([\"When\", \"training\", \"language\", \"models,\", \"tokenization\", \"choices\", \"can\", \"greatly\", \"affect\", \"performance,\", \"memory\", \"usage,\", \"and\", \"generalization;\", \"understanding\", \"subword\", \"algorithms\", \"and\", \"OOV\", \"behavior\", \"helps\", \"practitioners\", \"make\", \"informed\", \"trade-offs\", \"for\", \"their\", \"applications.\"]),\n",
    "]\n",
    "\n",
    "def show_token_lists(text):\n",
    "    enc = tokenizers['pretrained'](text)\n",
    "    ids = enc.get('input_ids')\n",
    "    gpt_toks = tokenizers['pretrained'].convert_ids_to_tokens(ids)\n",
    "    return {\n",
    "        'text': text,\n",
    "        'pretrained_tokens': gpt_toks,\n",
    "        'whitespace_tokens': tok_ws.tokens(text),\n",
    "        'sentencepiece_tokens': tok_sp.tokens(text),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e0391ebe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: In Python, list comprehensions provide a concise way to create lists. They are often faster than using loops, and they express intent clearly when mapping and filtering collections in everyday data processing tasks.\n",
      "\n",
      "Pretrained Tokens: ['In', 'ĠPython', ',', 'Ġlist', 'Ġcomprehens', 'ions', 'Ġprovide', 'Ġa', 'Ġconcise', 'Ġway', 'Ġto', 'Ġcreate', 'Ġlists', '.', 'ĠThey', 'Ġare', 'Ġoften', 'Ġfaster', 'Ġthan', 'Ġusing', 'Ġloops', ',', 'Ġand', 'Ġthey', 'Ġexpress', 'Ġintent', 'Ġclearly', 'Ġwhen', 'Ġmapping', 'Ġand', 'Ġfiltering', 'Ġcollections', 'Ġin', 'Ġeveryday', 'Ġdata', 'Ġprocessing', 'Ġtasks', '.']\n",
      "\n",
      "Whitespace Tokens: ['In', 'Python', ',', 'list', 'comprehensions', 'provide', 'a', 'concise', 'way', 'to', 'create', 'lists', '.', 'They', 'are', 'often', 'faster', 'than', 'using', 'loops', ',', 'and', 'they', 'express', 'intent', 'clearly', 'when', 'mapping', 'and', 'filtering', 'collections', 'in', 'everyday', 'data', 'processing', 'tasks', '.']\n",
      "\n",
      "SentencePiece Tokens: ['▁In', '▁Python', ',', '▁list', '▁comprehensions', '▁provide', '▁a', '▁concise', '▁way', '▁to', '▁create', '▁lists', '.', '▁They', '▁are', '▁often', '▁faster', '▁than', '▁using', '▁loops', ',', '▁and', '▁they', '▁express', '▁intent', '▁clearly', '▁when', '▁mapping', '▁and', '▁filtering', '▁collections', '▁in', '▁everyday', '▁data', '▁processing', '▁tasks', '.']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: The quick brown fox jumps over the lazy dog, while the curious cat watches from the windowsill, pondering why humans keep typing this sentence to test keyboards and fonts across different systems.\n",
      "\n",
      "Pretrained Tokens: ['The', 'Ġquick', 'Ġbrown', 'Ġfox', 'Ġjumps', 'Ġover', 'Ġthe', 'Ġlazy', 'Ġdog', ',', 'Ġwhile', 'Ġthe', 'Ġcurious', 'Ġcat', 'Ġwatches', 'Ġfrom', 'Ġthe', 'Ġwindows', 'ill', ',', 'Ġpond', 'ering', 'Ġwhy', 'Ġhumans', 'Ġkeep', 'Ġtyping', 'Ġthis', 'Ġsentence', 'Ġto', 'Ġtest', 'Ġkeyboards', 'Ġand', 'Ġfonts', 'Ġacross', 'Ġdifferent', 'Ġsystems', '.']\n",
      "\n",
      "Whitespace Tokens: ['The', 'quick', 'brown', 'fox', 'jumps', 'over', 'the', 'lazy', 'dog', ',', 'while', 'the', 'curious', 'cat', 'watches', 'from', 'the', '<UNK>', ',', '<UNK>', 'why', 'humans', 'keep', 'typing', 'this', 'sentence', 'to', 'test', 'keyboards', 'and', 'fonts', 'across', 'different', 'systems', '.']\n",
      "\n",
      "SentencePiece Tokens: ['▁The', '▁quick', '▁brow', 'n', '▁fox', '▁jumps', '▁over', '▁the', '▁lazy', '▁dog', ',', '▁while', '▁the', '▁curious', '▁cat', '▁watches', '▁from', '▁the', '▁windows', 'ill', ',', '▁pon', 'dering', '▁why', '▁humans', '▁keep', '▁typing', '▁this', '▁sent', 'ence', '▁to', '▁test', '▁keyboards', '▁and', '▁fonts', '▁across', '▁different', '▁systems', '.']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Text: When training language models, tokenization choices can greatly affect performance, memory usage, and generalization; understanding subword algorithms and OOV behavior helps practitioners make informed trade-offs for their applications.\n",
      "\n",
      "Pretrained Tokens: ['When', 'Ġtraining', 'Ġlanguage', 'Ġmodels', ',', 'Ġtoken', 'ization', 'Ġchoices', 'Ġcan', 'Ġgreatly', 'Ġaffect', 'Ġperformance', ',', 'Ġmemory', 'Ġusage', ',', 'Ġand', 'Ġgeneral', 'ization', ';', 'Ġunderstanding', 'Ġsub', 'word', 'Ġalgorithms', 'Ġand', 'ĠO', 'OV', 'Ġbehavior', 'Ġhelps', 'Ġpractitioners', 'Ġmake', 'Ġinformed', 'Ġtrade', '-', 'offs', 'Ġfor', 'Ġtheir', 'Ġapplications', '.']\n",
      "\n",
      "Whitespace Tokens: ['When', 'training', 'language', 'models', ',', '<UNK>', 'choices', 'can', 'greatly', 'affect', 'performance', ',', 'memory', 'usage', ',', 'and', '<UNK>', ';', 'understanding', '<UNK>', 'algorithms', 'and', '<UNK>', 'behavior', 'helps', '<UNK>', 'make', 'informed', 'trade', '-', 'offs', 'for', 'their', 'applications', '.']\n",
      "\n",
      "SentencePiece Tokens: ['▁When', '▁training', '▁language', '▁models', ',', '▁token', 'ization', '▁choices', '▁can', '▁greatly', '▁affect', '▁performance', ',', '▁memory', '▁usage', ',', '▁and', '▁general', 'ization', ';', '▁understanding', '▁sub', 'word', '▁algorithms', '▁and', '▁OO', 'V', '▁behavior', '▁helps', '▁pract', 'ition', 'ers', '▁make', '▁informed', '▁trade', '-', 'offs', '▁for', '▁their', '▁applications', '.']\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "qual_tokens = [show_token_lists(s) for s in long_samples]\n",
    "\n",
    "# Print the formatted tokens\n",
    "for item in qual_tokens:\n",
    "    print(f\"Text: {item['text']}\\n\")\n",
    "    print(f\"Pretrained Tokens: {item['pretrained_tokens']}\\n\")\n",
    "    print(f\"Whitespace Tokens: {item['whitespace_tokens']}\\n\")\n",
    "    print(f\"SentencePiece Tokens: {item['sentencepiece_tokens']}\\n\")\n",
    "    print(\"-\" * 80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173745f9",
   "metadata": {},
   "source": [
    "7. Model efficiency metrics (speed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4fa1e1c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device for speed measurements: cuda\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'pretrained': {'forward_tokens_per_s': 28137.579700956503,\n",
       "  'gen_ms_per_token': 7.418825477361679,\n",
       "  'train_ms_per_step': 215.43309688568115},\n",
       " 'whitespace': {'forward_tokens_per_s': 50395.25724804013,\n",
       "  'gen_ms_per_token': 6.905669718980789,\n",
       "  'train_ms_per_step': 142.32418537139893},\n",
       " 'sentencepiece': {'forward_tokens_per_s': 27669.564236477687,\n",
       "  'gen_ms_per_token': 7.586944103240967,\n",
       "  'train_ms_per_step': 243.5544729232788}}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speed = {}\n",
    "\n",
    "dev = best_device()\n",
    "print('Using device for speed measurements:', dev)\n",
    "\n",
    "for name, tok in tokenizers.items():\n",
    "    model, cfg = build_model(tokenizer_vocab[name], tokenizer_pad[name])\n",
    "    state = torch.load(final_weights[name], map_location='cpu')\n",
    "\n",
    "    model.load_state_dict(state)\n",
    "    model.to(dev)\n",
    "    model.eval()\n",
    "\n",
    "    thr = measure_throughput(model, cfg['vocab_size'], \n",
    "                             seq_len=256, batch_size=8, iters=20)\n",
    "    ms_gen = measure_generation_latency(model, cfg['vocab_size'], \n",
    "                                        prompt_len=16, new_tokens=64, iters=5)\n",
    "    ms_step = measure_training_step_time(model, cfg['vocab_size'], \n",
    "                                         seq_len=256, batch_size=8, iters=10)\n",
    "\n",
    "    speed[name] = {'forward_tokens_per_s': thr, \n",
    "                   'gen_ms_per_token': ms_gen, \n",
    "                   'train_ms_per_step': ms_step}\n",
    "\n",
    "speed"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
